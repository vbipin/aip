{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bandits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vbipin/aip/blob/master/bandits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxdqaSEKMUOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eJrDs86MZuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFu1RcglMctB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Can we do some bandit problems\n",
        "#K armed bandits Ch5 Sutton Barto"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA8H8LN1Meau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KArmedBandit :\n",
        "    def __init__(self, K=10, random_seed=100) :\n",
        "        self.K = K\n",
        "        \n",
        "        #xxx\n",
        "        np.random.seed(random_seed)\n",
        "        \n",
        "        #we select the mean of the arms according to a normal dist\n",
        "        self.loc = scipy.stats.norm.rvs(loc=0, size=K)\n",
        "\n",
        "        \n",
        "    def pull(self, k) : #pull the kth lever\n",
        "        return scipy.stats.norm.rvs(loc=self.loc[k], size=1)[0]\n",
        "    \n",
        "    def pull_all(self) : #pull all the arms once and return the values\n",
        "        return [ self.pull(i) for i in range(self.K) ]\n",
        "    \n",
        "#ban = KArmedBandit()\n",
        "#ban.pull(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1wpFZbcMgMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oracle(bandit) :\n",
        "    \"\"\"oracle will pull the best arm always\"\"\"\n",
        "    best_arm = np.argmax(bandit.loc)\n",
        "    return best_arm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lijTIcC8MjVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######## Experimental. May be wrong "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLNr02M9MqYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def greedy_action(bandit, Q) :\n",
        "    arm = np.argmax(Q)\n",
        "    return arm\n",
        "\n",
        "def epsilon_greedy_action(bandit, Q, epsilon) :\n",
        "    if np.random.random() < epsilon : #we act randomly by choosing one arm randomly\n",
        "        arm = np.random.randint(0,bandit.K)\n",
        "    else : #we act greedy; that is we choose the currently best available arm\n",
        "        arm = greedy_action(bandit, Q)\n",
        "    return arm\n",
        "\n",
        "def decay_epsilon_greedy_action(bandit, Q, count, temp) :\n",
        "    epsilon = 1/count**temp\n",
        "    if np.random.random() < epsilon : #we act randomly by choosing one arm randomly\n",
        "        arm = np.random.randint(0,bandit.K)\n",
        "    else : #we act greedy; that is we choose the currently best available arm\n",
        "        arm = greedy_action(bandit, Q)\n",
        "    return arm\n",
        "\n",
        "\n",
        "def UCB(bandit, Q, count, N, c=2) :\n",
        "    ext = np.array([ 5 for _ in range(len(N))])\n",
        "    for i in range(len(N)) :\n",
        "        if N[i] >0 :\n",
        "            ext[i] = c * np.sqrt(np.log(count)/N[i])\n",
        "    \n",
        "    arm = np.argmax(Q+ext)\n",
        "    return arm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sihYQVnMrJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learning(bandit, niterations, algorithm, optimistic_init=0) :\n",
        "    \n",
        "    N = [ 0 for _ in range(bandit.K) ] #initialize the values to zero\n",
        "    Q = [ optimistic_init for _ in range(bandit.K) ] #initialize the values to zero\n",
        "    V = [ 0 for _ in range(bandit.K) ] #initialize the values to zero\n",
        "    R = []\n",
        "    A = []\n",
        "    #now onwards we act greedily\n",
        "    for c in range(1,niterations+1) :\n",
        "        arm = algorithm(bandit, Q=Q, t=c, N=N)\n",
        "        N[arm] += 1\n",
        "        \n",
        "        sample = bandit.pull(arm)\n",
        "        R.append(sample)\n",
        "        A.append(arm)\n",
        "        \n",
        "        V[arm] += sample\n",
        "        Q[arm] = Q[arm] + (sample - Q[arm])/N[arm]\n",
        "        \n",
        "    \n",
        "    return Q, R, A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXdvEvx7MtSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "algorithms = [\n",
        "    lambda b, c: learning(b,c, lambda bandit,Q,t,N: oracle(bandit)),\n",
        "    lambda b, c: learning(b,c, lambda bandit,Q,t,N: UCB(bandit,Q, count=t, N=N)),\n",
        "    lambda b, c: learning(b,c, lambda bandit,Q,t,N: decay_epsilon_greedy_action(bandit,Q, count=t, temp=0.75)),\n",
        "    lambda b, c: learning(b,c, lambda bandit,Q,t,N: greedy_action(bandit,Q)),\n",
        "    #\n",
        "    lambda b, c: learning(b,c, lambda bandit,Q,t,N: greedy_action(bandit,Q),optimistic_init=5),\n",
        "    lambda b, c: learning(b,c, lambda bandit,Q,t,N: epsilon_greedy_action(bandit,Q, epsilon=0.1)),\n",
        "    \n",
        "    #lambda b, c: learning(b,c, lambda bandit,Q,t,N: epsilon_greedy_action(bandit,Q, epsilon=0.1)),\n",
        "    #lambda b, c: learning(b,c, lambda bandit,Q,t,N: epsilon_greedy_action(bandit,Q, epsilon=0.1), optimistic_init=5),\n",
        "    #lambda b, c: learning(b,c, lambda bandit,Q,t,N: epsilon_greedy_action(bandit,Q, epsilon=0.01)),\n",
        "    #lambda b, c: learning(b,c, lambda bandit,Q,t,N: decay_epsilon_greedy_action(bandit,Q, count=t, temp=0.75)),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvX6ocTjMvnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average_reward(r) :\n",
        "    s = 0\n",
        "    ar = [] #average reward\n",
        "    for i in range(len(r)) :\n",
        "        s += r[i]\n",
        "        ar.append( s/(i+1) )\n",
        "    return ar\n",
        "    \n",
        "def run_experiment_average_reward( algorithms=[], n_trials=1000, count=1000, random_seed=1234 ) :\n",
        "    exp = [[] for _ in range(len(algorithms)) ]\n",
        "    for i in range(n_trials) :\n",
        "        ban = KArmedBandit(random_seed=i+random_seed)\n",
        "        \n",
        "        for j, algo in enumerate(algorithms) :\n",
        "            q,r,a = algo(ban, count)\n",
        "            ar = average_reward(r)\n",
        "        \n",
        "            exp[j].append(ar)\n",
        "    return [ np.mean(e, axis=0) for e in exp ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mz-hQn7Mx0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_trials = 1000\n",
        "count = 1000\n",
        "l = run_experiment_average_reward( algorithms, n_trials, count, random_seed=29999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfa2EQF9NjN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(count), l[1]) #ucb, blue\n",
        "plt.plot(range(count), l[2]) #decay epsilon, orange\n",
        "plt.plot(range(count), l[3]) #greedy, green\n",
        "plt.plot(range(count), l[4]) #greedy with optimistic init red\n",
        "plt.plot(range(count), l[5]) #epsilon greedy 0.1 purple\n",
        "#plt.plot(range(count), l[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJfBwZefM0Ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}